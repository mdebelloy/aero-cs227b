<html>

<!--=======================================================================-->

<head>
  <title>Aero</title>
  <script type='text/javascript' src='http://epilog.stanford.edu/javascript/epilog.js'></script>
  <script type='text/javascript' src='http://gamemaster.stanford.edu/javascript/localstorage.js'></script>
  <script type='text/javascript' src='http://gamemaster.stanford.edu/interpreter/general.js'></script>
  <script type='text/javascript'>
//==============================================================================


var manager = 'manager';
var player = 'aero';

var role = 'robot';
var rules = [];
var startclock = 10;
var playclock = 10;

var library = [];
var roles = [];
var state = [];

//==============================================================================
/*
Writeup:

1. The pessimistic evaluation function is very simple, returning the reward for
terminal states and 0 for all non-terminal states.

2. Our mobility function returns a score from 0 to 100 based on the percentage
of moves that are feasible in the current game state. If this player is the
active player, the score assigned is equal to this percentage; otherwise, the
score is equal to 100 minus this percentage.

3. The intermediate reward function simply returns the reward value at the 
current state, regardless of if the current state is terminal.

4. The bounded depth minimax player we created explores the game tree to depth 3.
Terminal states are given their true score; if a terminal state is not reached
and we are at max depth, the state is evaluated as follows:

function evaluate(role, state) {
  return mobilityCoef * mobility(role, state, library) + (1 - mobilityCoef) * intermediate_reward(role, state);
}

Currently, we have mobilityCoef set to 0.5.

5. The iterative deepening player we built uses bounded depth, increasing the
depth until a time deadline is reached. Once the deadline is passed, the player
returns the current score value. We have also implemented a penalty for redoing
the same actions and an early callback when the entire game tree is discovered
into our iterative deepening player.

6. The persistent tree search player explores branches based on which available
node has the highest evaluation function value, using the same evaluation function
as our bounded depth and iterative deepening players. This evaluation function
takes into account both mobility and the intermediate reward value, therefore
providing a balance between exploitation and exploration in choosing the next
branch to explore.


/* PESSIMISTIC EVAL
function pessimistic_eval (role, state) {
    var state_value = 0;
    if (findterminalp(state, library)) {
        state_value = goal(role, state);
    }
    value(state)=state_value;
}
*/

/* MOBILITY FUNCTION
function mobility (role, state) {
  var actions = findlegals(role,state,library);
  var feasibles = findactions(role,library);

  var active = findcontrol(state,library); 
  var score = 0;

  if (active === role) {
    score = (actions.length/feasibles.length) * 100;
  } else {
    score = (100 - actions.length/feasibles.length) * 100;
  }
  return score;
}
}
*/

/* INTERMEDIATE REWARD
function intermediate_reward (role, state) {
    return findreward(role, state, library);
}
*/


/*  BOUNDED DEPTH MINIMAX
function playminimaxdepth (role)
  {var actions = shuffle(findlegals(state,library));
  if (actions.length===0) {return false};
  if (actions.length===1) {return actions[0]};
  var action = actions[0];
  var score = 0;
  var depth = 3;
  nodes = 0
  for (var i=0; i<actions.length; i++)
      {//console.log(grind(actions[i]));
        var newstate = simulate(actions[i],state,library);
        var newscore = minimaxdepth(role,newstate,depth);
        //console.log(newscore);
        if (newscore===100) {return actions[i]};
        if (newscore>score) {action = actions[i]; score = newscore}};
  return action}
*/

//==============================================================================




/*  ITERATIVE DEEPENING WITH PENALTY FOR REDOING THE SAME ACTIONS AND EARLY CALLBACK WHEN FULL TREE IS DISCOVERED

var nodes = 0;
var terminals = 0;
var elapsed = 0;
var mobilityCoef = 0.5;
var maxNodes = 0;
var visitedStates = {};


function intermediate_reward (role, state) {
    return findreward(role, state, library) * 1;
}

function mobility (r, state, library) {
  var actions = findlegals(state,library);
  var feasibles = findactions(library);

  if (r === role) {
    return (actions.length/feasibles.length) * 100
  } else {
    return 100 - (actions.length/feasibles.length) * 100
  }
}




function playIterativeDeepening(role) {
  var actions = shuffle(findlegals(state, library));
  if (actions.length === 0) { return false; }
  if (actions.length === 1) { return actions[0]; }
  var deadline = Date.now() + (playclock - 1) * 1000;
  var bestAction = actions[0];
  var bestScore = -Infinity;
  for (var depth = 1; depth <= 10; depth++) {
    console.log("Starting depth ", depth)
    nodes = 0;
    terminals = 0;
    var timeOut = false;
    for (var i = 0; i < actions.length; i++) {
      var newstate = simulate(actions[i], state, library);
      var score = minimaxdepth(role, newstate, depth, deadline);
      if (score === false) {
        timeOut = true;
        break;
      }
      // can we assume min-max scores are 0-100??
      //if (score === 100) {
      //  return actions[i];
      //}
      

      if (score > bestScore) {
        var newStateSignature = JSON.stringify(actions[i]);
        if (newStateSignature in visitedStates && visitedStates[newStateSignature] == role) {
          score *= 0.8; 
        }
        if(score > bestScore){
          bestAction = actions[i];
          bestScore = score;
        }
      }
    }
    if (timeOut || (maxNodes === nodes)) {
      break
    }
    maxNodes = nodes;
    console.log("Finished depth: ", depth, ", Found: ", nodes, " nodes, Best score: ", bestScore);
  }
  return bestAction;
}


function minimaxdepth(role, state, depth, deadline) {
  if (Date.now() > deadline) {
    return false;
  }
  nodes++;
  if (findterminalp(state, library)) {
    terminals++;
    return findreward(role, state, library) * 1;
  }
  if (depth <= 0) {
    terminals++;
    return mobilityCoef * mobility(role, state, library) + (1-mobilityCoef) * intermediate_reward(role, state);
  }
  var active = findcontrol(state, library);
  if (active === role) {
    return maximizedepth(active, role, state, depth, deadline);
  }
  return minimizedepth(active, role, state, depth, deadline);
}


function maximizedepth(active, role, state, depth, deadline) {
  var actions = findlegals(state, library);
  if (actions.length === 0) {
    return 0;
  }
  var score = -Infinity;
  for (var i = 0; i < actions.length; i++) {
    if (Date.now() > deadline) {
      return false;
    }
    var newstate = simulate(actions[i], state, library);
    var newscore = minimaxdepth(role, newstate, depth - 1, deadline);
    if (newscore === false) {
      return false;
    }
    // can we assume min-max scores are 0-100??
    //if (newscore === 100) {
    //  return 100;
    //}
    
    if (newscore > score) {
      score = newscore;
    }
  }
  return score;
}


function minimizedepth(active, role, state, depth, deadline) {
  var actions = findlegals(state, library);
  if (actions.length === 0) {
    return 0;
  }
  var score = Infinity;
  for (var i = 0; i < actions.length; i++) {
    if (Date.now() > deadline) {
      return false;
    }
    var newstate = simulate(actions[i], state, library);
    var newscore = minimaxdepth(role, newstate, depth - 1, deadline);
    if (newscore === false) {
      return false;
    }
    // can we assume min-max scores are 0-100??
    //if (newscore === 0) {
    //  return 0;
    //}
    
    if (newscore < score) {
      score = newscore;
    }
  }
  return score;
}


function play(move) {
  if (move !== nil) {
      var stateSignature = JSON.stringify(move);
      visitedStates[stateSignature] = role;
      compexecute(move, state, library)

  };

  if (findcontrol(state, library) !== role) {
      return false
  };

  return playIterativeDeepening(role)
}

*/


var tree;
var mobilityCoef = 0.5;

//Persistant Tree
function play(move) {
  if (move !== nil) {
    tree = subtree(move, tree); 
    state = tree.state
  }
  else{
    tree = makenode(state,findcontrol(state,library),evaluate(role, state));
  };
  if (findcontrol(state, library) !== role) {
    return false
  };
  var deadline = Date.now() + (playclock - 2) * 1000;
  while (Date.now() < deadline) {
    process(tree)
  };
  return selectaction(tree);
}


function mobility (r, state, library) {
  var actions = findlegals(state,library);
  var feasibles = findactions(library);

  if (r === role) {
    return (actions.length/feasibles.length) * 100
  } else {
    return 100 - (actions.length/feasibles.length) * 100
  }
}


function intermediate_reward (role, state) {
    return findreward(role, state, library) * 1;
}

function evaluate(role, state) {
  return mobilityCoef * mobility(role, state, library) + (1 - mobilityCoef) * intermediate_reward(role, state);
}

function selectaction(node) {
  var action = node.actions[0];
  var score = node.children[0].utility;
  for (var i = 1; i < node.children.length; i++) {
    var newscore = node.children[i].utility;
    if (newscore > score) {
      action = node.actions[i];
      score = newscore
    }
  };
  return action;
}

function selectnode(node) {
  var child = node.children[0];
  var visits = node.children[0].visits;
  for (var i = 1; i < node.children.length; i++) {
    var newvisits = node.children[i].visits;
    if (newvisits < visits) {
      child = node.children[i];
      visits = newvisits
    }
  };
  return child;
}

function subtree(move, node) {
  if (node.children.length === 0) {
    expand(node)
  };
  for (var i = 0; i < node.actions.length; i++) {
    if (equalp(move, node.actions[i])) {
      return node.children[i]
    }
  }
  return node;
}

function select(node) {
  var total = node.visits;
  var child = node.children[0];
  var score = value(child.utility, child.visits, total);
  for (var i = 1; i < node.children.length; i++) {
    var newchild = node.children[i];
    var newvalue = newchild.utility;
    var newvisits = newchild.visits;
    var newscore = value(newvalue, newvisits, total);
    if (newscore > score) {
      child = newchild;
      score = newscore
    }
  };
  return child;
}

function makenode(state, mover, reward) {
  return {
    state: state,
    actions: [],
    children: [],
    mover: mover,
    utility: reward,
    visits: 0
  }
}

function process(node) {
  if (node.children.length === 0) {
    expand(node);
    return update(node);
  }
  else {
    var child = select(node);
    var result = process(child);
    return update(node);
  }
}

function expand(node) {
  var state = node.state;
  var mover = node.mover;
  var actions = findlegals(state, library);
  actions = shuffle(actions);
  
  for (var i = 0; i < actions.length; i++) {
    var newstate = simulate(actions[i],state,library)
    node.actions.push(actions[i]);
    node.children.push(makenode(newstate, findcontrol(newstate, library), evaluate(role, newstate)));
  }
  
  return true;
}

function scoremax(node) {
  var score = node.children[0].utility;
  for (var i = 1; i < node.children.length; i++) {
    var newscore = node.children[i].utility;
    if (newscore > score) {
      score = newscore;
    }
  }
  return score;
}

function scoremin(node) {
  var score = node.children[0].utility;
  for (var i = 1; i < node.children.length; i++) {
    var newscore = node.children[i].utility;
    if (newscore < score) {
      score = newscore;
    }
  }
  return score;
}

function update(node) {
  if (node.mover === role) {
    node.utility = scoremax(node)
  } else {
    node.utility = scoremin(node)
  };
  node.visits = node.visits + 1;
  return true;
}



function value(utility, visits, total) {
  var score = (utility + Math.round((1 - visits / total) * 100));
  return score;
}


function shuffle (array)
  {for (var i = array.length-1; i>0; i--)
      {var j = Math.floor(Math.random() * (i + 1));
        var temp = array[i];
        array[i] = array[j];
        array[j] = temp};
  return array}


//==============================================================================

function ping() {
    return 'ready'
}

function start(r, rs, sc, pc) {
    role = r;
    library = definemorerules([], rs.slice(1));
    roles = findroles(library);
    state = findinits(library);
    startclock = numberize(sc);
    playclock = numberize(pc);
    return 'ready'
}



function stop(move) {
    return false
}

function abort() {
    return false
}


//==============================================================================
// End of player code
//==============================================================================
  </script>
</head>

<!--=======================================================================-->

<body bgcolor='#aabbbb' onload='doinitialize()'>
  <center>
    <table width='720' cellspacing='0' cellpadding='40' bgcolor='#ffffff'>
      <tr>
        <td>

<!--=======================================================================-->

<center>
  <table width='640' cellpadding='0'>
    <tr>
      <td width='180' align='center' valign='center'>
        <img width='130' src='http://gamemaster.stanford.edu/images/ggp.jpg'/>
      </td>
      <td align='center'>
        <span style='font-size:18pt'>&nbsp;</span>
        <span style='font-size:32pt'>Gamemaster</span><br/>
      </td>
      <td width='180' align='center' style='color:#000066;font-size:18px'>
        <i>General<br/>Game<br/>Playing</i>
      </td>
    </tr>
  </table>
</center>

<!--=======================================================================-->

<br/>
<table width='640' cellpadding='8' cellspacing='0' bgcolor='#f4f8f8' border='1'>
  <tr height='40'>
     <td align='center'>
<table style='color:#000066;font-size:18px'>
  <tr>
    <td>
Protocol: localstorage<br/>
Metagamer: none<br/>
Strategy: custom<br/>
Identifier: <span id='player'>aero</span> <img src="http://gamemaster.stanford.edu/images/pencil.gif" onclick='doplayer()'/>
    </td>
  </tr>
</table>
    </td>
  </tr>
</table>
<br/>

<!--=======================================================================-->

<center>
  <br/>
  <textarea id='transcript' style='font-family:courier' rows='30' cols='80' readonly></textarea>
</center>

<!--=======================================================================-->

        </td>
      </tr>
    </table>
  </center>
</body>

<!--=======================================================================-->

</html>
